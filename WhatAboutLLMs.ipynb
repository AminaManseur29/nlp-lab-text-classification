{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb73f41b-f54f-4201-a179-9c738fbcba4e",
   "metadata": {},
   "source": [
    "# What about the LLMs?\n",
    "\n",
    "LLMs are reputed to have revolutionised automatic language processing. Since the introduction of BERT-type models, all language processing applications have been based on LLMs, of varying degrees of sophistication and size. These models are trained on multiple tasks and are therefore capable of performing new tasks without learning, simply from a prompt. This is known as \"zero-shot learning\" because there is no learning phase as such. We are going to test these models on our classification task.\n",
    "\n",
    "Huggingface is a Franco-American company that develops tools for building applications based on Deep Learning. In particular, it hosts the huggingface.co portal, which contains numerous Deep Learning models. These models can be used very easily thanks to the [Transformer] library (https://huggingface.co/docs/transformers/quicktour) developed by HuggingFace.\n",
    "\n",
    "Using a transform model in zero-shot learning with HuggingFace is very simple: [see documentation](https://huggingface.co/tasks/zero-shot-classification)\n",
    "\n",
    "However, you need to choose a suitable model from the list of models compatible with Zero-Shot classification. HuggingFace offers [numerous models](https://huggingface.co/models?pipeline_tag=zero-shot-classification). \n",
    "\n",
    "The classes proposed to the model must also provide sufficient semantic information for the model to understand them.\n",
    "\n",
    "**Question**:\n",
    "\n",
    "* Write a code to classify an example of text from an article in Le Monde using a model transformed using zero-sot learning with the HuggingFace library.\n",
    "* choose a model and explain your choice\n",
    "* choose a formulation for the classes to be predicted\n",
    "* show that the model predicts a class for the text of the article (correct or incorrect, analyse the results)\n",
    "* evaluate the performance of your model on 100 articles (a test set).\n",
    "* note model sizes, processing times and classification results\n",
    "\n",
    "\n",
    "Notes :\n",
    "* make sure that you use the correct Tokenizer when using a model \n",
    "* start testing with a small number of articles and the first 100's of characters for faster experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe910b5-949d-455d-b001-e4682f8a693c",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
